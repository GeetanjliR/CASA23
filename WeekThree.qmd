# Week Three: Remote Sensing Data: Corrections and Imaging

## Summary

Before going ahead to understand the image correction and processing, it is worth knowing few interesting things about the remote sensing or earth observation.

```{r echo=FALSE, out.width='100%', fig.align='center'}

knitr::include_graphics('img/Dis.jpg')

```

However, there were new information came to light for me as can be seen below.

```{r echo=FALSE, out.width='100%', fig.align='center'}

knitr::include_graphics('img/Fun.jpg')

```

[@benefits2021]

### Correction

The entire process has been explained in figure-1. Corrections are required because satellite imagery can contain errors from various sources, including the sensor, atmosphere, and terrain. Scan line correction (SLC) is applied to align images from whisk broom, spotlight, or across-track scanners. This alignment is achieved through regression, where the vertical differences between the blue line and residuals should sum to 0. Therefore, these errors must be corrected as necessary to ensure accuracy. Contextualizing the use of imagery is essential for this purpose. Additionally, linear regression is commonly employed for modeling and then resampling the data.

A **Geometric Correction** is necessary to address image distortions caused by factors such as the coordinate reference system, view angle, topography, wind, and rotation of the Earth. This correction involves identifying Ground Control Points (GPS) to match known points in the image with reference data, such as a local map, another image, or GPS data from a handheld device.

The second correction, **Atmospheric Correction (AC)**, is essential to mitigate environmental attenuation, including atmospheric scattering and topographic effects. **Relative correction** methods, such as Dark Object Subtraction (DOS) or histogram adjustment, involve identifying the darkest value in each band and subtracting it from each pixel. **Pseudo-Invariant Features (PIFs)** are also used for relative correction. **Absolute Correction** entails converting digital brightness values into scaled surface reflectance. **Empirical Line Correction** involves in-situ measurements using a field spectrometer, conducted simultaneously with satellite overpasses. Linear regression is then applied to correlate these measurements with the raw digital number data from the satellite.

The third correction, **Orthorectification / Topographic Correction**, is essential because imagery taken at an angle can cause distortions. Georectification assigns coordinates to an image, while orthorectification removes these distortions.

Lastly, **Radiometric Calibration** involves pre-calibrating sensors in a lab before launch and then using these measurements to adjust sensor data. This process involves capturing image brightness and distribution as a Digital Number (DN) by the sensors, which is then converted to spectral radiance through radiometric calibration.

### Joining data sets

To create a seamless mosaic or image(s) in Remote Sensing, the process of feathering images together is utilized. The seamline serves as the dividing line between a base image and the "other" or second image, with a recommended 20-30 percent overlap, from which a histogram is extracted. Subsequently, a histogram matching algorithm is applied to achieve similar brightness values between the two images, followed by the feathering process.

**Enhancements** of imagery can be achieved based on the energy reflected and the contrast between features. Various enhancements include NDVI, NBR, and local enhancements such as edge enhancements using techniques like embossing or filtering. **Principle Component Analysis (PCA)** serves as a method to remove variance from dependent variables and is also utilized to group similar variables, such as social or environmental variables. A PCA (figure-2) and texture (figure-3) analysis has been show for Delhi, India as carried during the practilce CASA0023.

Figure-1: Remote Sensing Process

```{r echo=FALSE, out.width='100%', fig.align='center'}

knitr::include_graphics('img/Slide2.jpg')

```

Figure-2: NDVI Enhancement for Delhi, India

```{r echo=FALSE, out.width='100%', fig.align='center'}

knitr::include_graphics('img/EnhancementNDVI.png')

```

Figure-3: PCA for Delhi, India

```{r echo=FALSE, out.width='100%', fig.align='center'}

knitr::include_graphics('img/PCA_Predict_Plot.jpg')

```

Figure-4: Texture Analysis for Delhi India

```{r echo=FALSE, out.width='100%', fig.align='center'}

knitr::include_graphics('img/Texture.jpg')

```

## Application

In T. Therry's discussion on three-dimensional (3D) **geometric processing and ortho-rectification** of remote sensing (RS) data, the author emphasizes the importance of this process as the first step in multi-source multi-format data fusion within geographic information systems. The fusion of image data (such as visible and microwave, panchromatic and multi-bands, polarimetric bands, passive and active, etc.), along with their metadata (GPS, star trackers, inertial systems, lens and focal plane data, etc.), and associated 3D cartographic data (ground control points, contour lines, digital terrain models (DEM), planimetric features, etc.), is essential for performing precise 3D geometric correction and subsequent ortho-rectification processes using DEM. The article provides insights into the state-of-the-art of geometric correction, including sources of geometric distortions, mathematical models, methods, algorithms, and processing steps, while also addressing error propagation during the fusion of RS and cartographic data from image acquisition to ortho-rectification processes.

In another article by [@pahlevan2017], the application of **spectroradiometer** is discussed, particularly focusing on the Operational Land Imager (OLI) onboard Landsat-8. The OLI provides high-quality aquatic science products, with remote sensing reflectance (Rrs) being a critical product, defined as the ratio of water-leaving radiance to total downwelling irradiance just above water. The authors extensively assess the quality of Rrs products derived from OLI imagery under near-ideal atmospheric conditions in moderately turbid waters. They note slight across-track non-uniformities (\<1%) associated with OLI scenes in the blue bands, and observe that OLI products generally exhibit larger radiometric responses in the blue channels compared to Aqua platform (MODISA) products. After implementing updated vicarious calibration gains and accounting for across-track non-uniformities, matchup analyses using independent **in-situ validation data confirm improvements in Rrs products**. These findings support the high-fidelity of OLI-derived aquatic science products, demonstrating robust atmospheric correction methods and consistent product quality across OLI's imaging swath.

## Reflection

In my previous experience, I utilized Google Earth images for spatial analysis, encountering challenges with angle correction, image distortion, and scaling. Overcoming these obstacles required a laborious process, including looping through corrections and downloading map sections for improved resolution to facilitate local-level spatial analysis, particularly for stitching basemaps. Fortunately, the recent lecture has significantly enhanced my understanding and proficiency in remote sensing (RS) and Earth observation (EO).

I now possess knowledge of various image correction and enhancement techniques. Moreover, I have gained insights into addressing challenges like cloudy conditions by leveraging SAR data, which I realize can also be applicable to mitigating issues during fog, smog, and smoke special of case in India. The concept of tiling resonates with me, and I found the Dark Object Subtraction (DOS) method for atmospheric correction particularly enlightening. Understanding subtle distinctions between key concepts such as radiance (or DN) versus reflectance has piqued my interest. Additionally, the practical application of various normalization indexes, such as NDVI, NDBI etc. which I encountered frequently in previous RS research, now holds greater significance for me.

**Footnote:** \* - Nadir means directly down Empirical Line Correction Topographic Correction Spot m Solar Zenith Angle describing illumination angle of source i.e., sun Digital Number (DN): different radio metric resolution DN is spectral radiance equals radiance calibration TOA is Topographical of Atmosphere reflectance is property of the material whereas radiance is light reflect from source as sun TOA reflectance in the air BOA: property of material DN is the roll number on the camera Hemispherical reflectance: all light enter the satellite or sensor Apperant Reflectance: solar azimuth = compass angle of the sun (N =0째) 90째 (E) at sunrise and 270째 (W) at sunset. See Azimuth Angle animation solar zenith = angle of local zenith (above the point on ground) and sun from vertical (90째 - elevation) Spectral radiance is the amount of light within a band from a sensor in the field of view (FOV) Radiance refers to any radiation leaving the Earth (i.e. upwelling, toward the sensor. It could be also called Top of Atmosphere (TOA) radiance. Irradiance, is used to describe downwelling radiation reaching the Earth from the sun. Reflectance is a property of a material. Digital number (DN): intensity of the electromagnetic radiation per pixel, pixel values that aren't calibrated and have no unit, have light source, effects of sensor + atmosphere + material, values range from 0 - 255 (Lansat 5) = 8 bit or 0 - 65536 Landsat 8 (12 bit)
