# WeekSeven: Classification-2 The Big Question

## Summary

Data processing is essential in handling EO data. When processing EO data, it's crucial to preprocess the data to correct for atmospheric effects, geometric distortions, and radiometric variations. This ensures that the data is suitable for analysis. Processing EO data involves various considerations, including data pre-processing, choosing between pixel and object-based analysis, addressing mixed pixels and objects, and assessing model accuracy using independent reference data and appropriate evaluation metrics. Additionally, accounting for spatial autocorrelation and using advanced techniques like OBIA and spatial cross-validation can enhance the accuracy of classification models.

### Object Based Image Analysis (OBIA)

Object-Based Image Analysis (OBIA) is an approach to image analysis that considers raster cells as part of objects on the ground rather than treating each cell independently. A raster cell does not directly represent an object on the ground but objects are represented by shapes based on the similarity (homogeneity) or difference (heterogeneity) of the cells, which are grouped into superpixels. The most common method for generating superpixels is the SLIC (Simple Linear Iterative Clustering) Algorithm. This algorithm works by placing regular points on the image and computing spatial distance and color difference to group pixels into homogeneous regions. Tools like Supercell's package facilitate the generation of superpixels and allow for customization of parameters such as the number of superpixels (K) and compactness, which balances spatial and color considerations. Before classification, features are often transformed, typically into the LAB color space, to enhance discrimination between objects based on color and spatial characteristics. After feature extraction, average values per object are computed, and classification methods similar to those used in pixel-based analysis can be applied to classify objects.OBIA allows for the computation of various metrics beyond average values, such as length-to-width ratio, to further characterize objects using additional metrics. There are several OBIA classifiers available, each employing slightly different processes. It's essential to choose a classifier that best suits the specific analysis needs and data characteristics. More advanced packages like SegOptim offer algorithms from other software for enhanced object-based analysis capabilities.

Figure-1: Object Based Image Analysis (OBIA)

```{r echo=FALSE, out.width='100%', fig.align='center'}

knitr::include_graphics('img/OBIA.jpg')

```

https://landinfo.com/image-classification-object-based-image-analysis-obia/

### Sub-Pixel Analysis

Subpixel analysis, also known as Spectral Mixture Analysis (SMA) or Linear Spectral Unmixing, is a method used to determine the proportions or abundances of different land cover types within a single pixel. This analysis calculates the proportion or abundance of different land cover types within a pixel based on the assumption that the reflectance measured at each pixel is a linear combination of endmembers weighted by their associated fractions. Endmembers are spectrally pure representations of different land cover types. Typically, a few endmembers are selected to represent the variability in spectral signatures across the image. The abundance of each endmember within a pixel is determined by multiplying the reflectance of each endmember by its fraction contribution to the best-fit mixed spectrum. It has few issues and consideration as pixel purity, number of endmembers and multiple endmember spectral analysis (MESMA). In pixel purity the subpixel analysis assumes that each pixel contains a mixture of endmembers, but in reality, pixels may contain spectrally pure or mixed endmembers, impacting the accuracy of the analysis. In the case of the number of endmembers, the selection of endmembers is crucial and depends on the complexity of the landscape. In urban areas, the V-I-S model (Vegetation-Impervious surface-Soil) is commonly used to simplify the process. Multiple Endmember Spectral Analysis (MESMA), allows for the use of multiple endmembers to better capture the spectral variability within a pixel. However, this approach increases computational complexity, and spectral libraries may be used to aid in endmember selection.Thus, careful consideration of pixel purity and endmember selection is necessary to ensure accurate results.

Figure-2: Sub-Pixel Analysis

```{r echo=FALSE, out.width='100%', fig.align='center'}

knitr::include_graphics('img/Sub.jpg')

```

https://www.researchgate.net/figure/Illustrating-the-difference-between-per-pixel-and-sub-pixel-classification-mapping_fig1_357114787

### Accuracy

Accuracy assessment in remote sensing involves assigning accuracy values to classification results, similar to the process in machine learning. Key metrics include Producer Accuracy (PA), User's Accuracy (UA), and Overall Accuracy (OA). Producer Accuracy (PA), also known as recall or true positive rate, measures the vertical accuracy of classification results. It assesses how well the classification results meet the expectations of the data creator. User's Accuracy (UA), also referred to as precision or positive predictive value, evaluates the horizontal accuracy of classification results. It measures the proportion of pixels that are correctly classified as a known class out of all pixels classified as that class. Overall Accuracy (OA) represents the combined fraction of correctly classified pixels across all land cover types.

In assessing accuracy, several terms are used to categorize correct and incorrect classifications:

True Positive (TP): The model predicts the positive class correctly. True Negative (TN): The model predicts the negative class correctly. False Positive (FP): The model predicts positive, but it is negative. False Negative (FN): The model predicts negative, but it is positive. Producer's and User's Accuracy are defined as follows:

Producer's Accuracy: TP / (TP + FN) User's Accuracy: TP / (TP + FP)

Errors of omission and commission are also considered. Errors of omission occur when a land cover type is omitted from the correct class. It is calculated as 100 - Producer's Accuracy. In contrast, errors of commission involve classified sites for incorrect classifications. It is computed as 100 - User's Accuracy. Additionally, the Kappa coefficient is used to assess the agreement between classification results and ground truth data.

Beyond traditional remote sensing accuracy assessment, considerations include the balance between recall (Producer Accuracy) and precision (User Accuracy). The Receiver Operating Characteristic (ROC) Curve and the Area Under the ROC Curve (AUC) are employed to evaluate model performance, especially in binary classification tasks. The ROC Curve plots the true positive rate against the false positive rate, while the AUC represents the probability that the model will rank a randomly chosen positive example higher than a randomly chosen negative example. A higher AUC indicates better model performance, with a perfect classifier achieving an AUC of 1.

#### Train and Test Split

A good approach in machine learning is to split the dataset into training and testing sets. This involves reserving a certain percentage of the original data for training the model and keeping the remaining portion for testing the model's performance. The training set is used to train the model's parameters, while the testing set evaluates the model's performance on unseen data.

#### Leave-One-Out Cross-Validation (LOOCV)

LOOCV is an extreme form of cross-validation suitable for smaller datasets. In LOOCV, each data point is used as the testing set once, while the rest of the data is used for training. This process is repeated for each data point, resulting in multiple rounds of training and testing.

#### Spatial Cross-Validation

Spatial cross-validation is a variation of traditional cross-validation that considers spatial relationships in the dataset. It involves partitioning the data into folds while ensuring spatial disjointness, typically using techniques like k-means clustering based on the number of points and a distance metric. This ensures that the training and testing data are not spatially correlated, preventing the model from overfitting to local spatial patterns. The process is illustrated in figure-3 for Delhi.

Figure-3: Accuracy, OBIA, Super-pixel Analysis for Delhi, India

```{r echo=FALSE, out.width='100%', fig.align='center'}

knitr::include_graphics('img/Classification2.jpg')

```

## Application

Research conducted by [@saba2022] explains how timely and exact delineation of landslides is imperative for decision-makers to respond effectively and swiftly to such disasters. Their team describes the virtues and drawbacks of pixel, sub-pixel, and Object-Based Image Analysis (OBIA)-based approaches for local to regional areas, highlighting the challenge of accuracy in extracting regional-level auxiliary datasets. Meanwhile, the investigation by [@qu2021] addresses concerns about the accuracy of extracting Land Use Land Cover (LULC) solely using spectral features of imagery due to heterogeneity in landforms for larger areas. They attempt to provide better results using open-source datasets in GEE, elucidating methods of pixel and object-based classification. The study area for the first paper is in Muzaffarabad, Pakistan (Lesser Himalayas), where they compare classification methods based on MLC (Maximum Likelihood Classifier), the Co-Registration of Optically Sensed Images and Correlation (COSI-Corr), and OBIA using SPOT and ASTER imagery. On the other hand, the second research focuses on LULC classification using medium-resolution imagery from Landsat-8 OLI data for the Yangtze River Delta in China.

Saba, S.B. et al. employed comparative classification techniques, including MLC, COSI-Corr, and OBIA using SPOT and ASTER imagery. Qu, L.A. et al. compared the improvement in accuracy of seven pixel-based and seven object-based random forest classification models. While Saba, S.B. et al. observed an overall accuracy improvement in landslide feature classification using satellite data, Qu, L.A. et al. discovered that the overall accuracy of LULC classification using GEE auxiliary datasets can be enhanced regardless of the types of auxiliary features.

Saba, S.B. et al. found that the OBIA classification yielded the highest overall accuracy at 91.4%, followed by sub-pixel COSI-Corr with 90.9%, and pixel-based classification with 80.8% accuracy. Similarly, Qu, L.A. et al. confirmed that object-based classification achieved higher overall accuracy compared to pixel-based classification.

The former group of authors also noted that the OBIA results are more spatially consistent than the pixel-based outcomes, which exhibit speckled pixel effects and are dependent on visual interpretation. The latter group stated that topographic features play the most crucial role in improving the overall accuracy of classification in both pixel- and object-based models incorporating all features. Furthermore, higher accuracy is achieved when the object-based method is used with only spectral data, although small objects on the ground cannot be adequately monitored. However, when combined with various types of auxiliary features, the object-based method can identify small objects while also achieving greater accuracy.

## Reflection

OBIA, or Object-Based Image Analysis, revolutionizes image analysis by treating raster cells as components of larger, coherent objects on the ground. This methodology goes beyond traditional pixel-based analysis by considering not only individual pixel values but also the spatial relationships and spectral characteristics of neighboring pixels.

In OBIA, the process typically begins with the generation of superpixels, which are clusters of pixels with similar spectral and spatial properties. These superpixels are then subjected to feature transformation, where various attributes such as color, texture, shape, and size are extracted to characterize the objects more comprehensively. Finally, classification techniques are applied to these transformed features to categorize the objects into meaningful classes or categories.

Unlike pixel-based analysis, which evaluates each pixel independently, OBIA groups pixels into objects based on their contextual information, leading to more accurate and semantically meaningful results. By considering the spatial context and spectral properties of objects, OBIA can capture complex patterns and structures in remote sensing data more effectively.

In summary, OBIA offers a powerful framework for extracting valuable insights from remote sensing imagery by leveraging spatial and spectral information to delineate and classify objects on the ground. Its ability to analyze imagery at the object level provides a more holistic understanding of the landscape, making it an indispensable tool for a wide range of applications in environmental monitoring, land cover classification, urban planning, and more.
